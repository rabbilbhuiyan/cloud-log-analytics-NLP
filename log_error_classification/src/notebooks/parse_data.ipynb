{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e30d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module and class\n",
    "from get_data import DataLoader\n",
    "\n",
    "# to ingnore the warning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37251cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the instance of class\n",
    "loaderInstance = DataLoader()\n",
    "\n",
    "# calling the instance of class\n",
    "data = loaderInstance.load_data()\n",
    "\n",
    "# print the output\n",
    "#data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b62afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "PROCESSED_DATA_PATH = r'C:\\Users\\rbhuiyan\\Desktop\\log_classification\\log_error_classification\\data\\processed'\n",
    "\n",
    "class DataParser():\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.input_dir = input_dir\n",
    "        #self.load_data()\n",
    "        self.PROCESSED_DATA_PATH = PROCESSED_DATA_PATH\n",
    "        self.parsed_data = None\n",
    "        #self.timestamp_data = None\n",
    "        self.parse_data()\n",
    "        self.create_label()\n",
    "        self.store_data()\n",
    "        #self.timestamp()\n",
    "        #self.create_label()\n",
    "        #pass\n",
    "    \n",
    "        \n",
    "\n",
    "    #Display and extract the features from the log data\n",
    "    def parse_data(self) ->pd.DataFrame:\n",
    "        '''\n",
    "        data parsing.\n",
    "        Args:\n",
    "            df {pandas.DataFrame}: dataset\n",
    "        Return:\n",
    "            pandas.Dataframe: updated data with new features\n",
    "        '''\n",
    "        \n",
    "        # copy the dataframe\n",
    "        parsed_data = data.copy()\n",
    "        \n",
    "        # spliting the data into variables\n",
    "        parsed_data[['timestamp', 'server','component','date', 'time', 'customer_ID','event', 'nova_compute', 'log_message']] = parsed_data['Column'].str.split(' ', 8, expand=True)\n",
    "        \n",
    "        # sub dataframe\n",
    "        parsed_data = parsed_data[['server','component','date', 'time', 'customer_ID', 'nova_compute', 'log_message']]\n",
    "        \n",
    "        # extracting the info within the square bracket\n",
    "        parsed_data['request_ID'] = parsed_data['log_message'].str.extract('\\[(.*?)\\]', expand=False).str.strip()\n",
    "        \n",
    "        # removing the square bracket and the contents within the square bracket\n",
    "        parsed_data['log_message'] = parsed_data['log_message'].str.replace(r'\\[.*?\\]','')\n",
    "\n",
    "        # Taking only first 100 characthers of the log message\n",
    "        parsed_data['log_message'] = parsed_data['log_message'].str[:100]\n",
    "\n",
    "        # stripping off everything after #\n",
    "        parsed_data['log_message'] = parsed_data['log_message'].str.split('#').str[0]\n",
    "        \n",
    "        ##########################\n",
    "        # deleting the non-date values: first make the non-dates to NaT value, then apply dropna() method\n",
    "        parsed_data['date'] = pd.to_datetime(parsed_data['date'], errors='coerce')\n",
    "        parsed_data = parsed_data.dropna(subset=['date'])\n",
    "\n",
    "        # creating a timestamp column\n",
    "        date_time=pd.to_datetime(parsed_data['date'].astype(str)+ ' '+ parsed_data['time'].astype(str))\n",
    "        parsed_data.insert(0, 'timestamp', date_time)\n",
    "\n",
    "        # droping the columns date and time\n",
    "        parsed_data.drop(['date','time'], axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "        return parsed_data\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def create_label(self) ->pd.DataFrame:\n",
    "    \n",
    "        labeled_data = DataParser.parse_data(self)\n",
    "        \n",
    "        conditions = [\n",
    "            (labeled_data['log_message'].str.contains('service status')),\n",
    "            #(df3_error['log_message_3'].str.contains('network cache')) & (df3_error['log_message_3'].str.contains('ConnectTimeout')),\n",
    "            (labeled_data['log_message'].str.contains('network cache')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager.update')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._heal')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._sync_scheduler')),\n",
    "            (labeled_data['log_message'].str.contains('ConnectTimeout')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._run_pending')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._cleanup_incomplete')),\n",
    "            (labeled_data['log_message'].str.contains('connection blocked')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._sync_power')),\n",
    "            (labeled_data['log_message'].str.contains('AMQP server on pouta2')),\n",
    "            (labeled_data['log_message'].str.contains('AMQP server on pouta1')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._run_image')),\n",
    "            (labeled_data['log_message'].str.contains('ComputeManager._cleanup_running')),\n",
    "            (labeled_data['log_message'].str.contains('Error updating resources for node')),\n",
    "            (labeled_data['log_message'].str.contains('Unable to access floating IP')),\n",
    "            (labeled_data['log_message'].str.contains('ProcessExecutionError')),\n",
    "            (labeled_data['log_message'].str.contains('InvalidSharedStorage_Remote')),\n",
    "            (labeled_data['log_message'].str.contains('Failed storing info cache'))]\n",
    "\n",
    "        # create a list of the values we want to assign for each condition\n",
    "        values = ['service status', 'network cache', 'CP update resource', 'CP heal instance', 'CP sync scheduler',\n",
    "                 'NC ConnectTimeout', 'CP run pending', 'CP clearup migrations', 'broker blocked connection','CP sync power',\n",
    "                 'AMQP server pouta2',  'AMQP server pouta1','CP run image cache','CP cleanup running instance','node updating',\n",
    "                 'floating IP access','ProcessExecutionError','InvalidSharedStorage_Remote', 'storing info cache']\n",
    "\n",
    "        # create a new column and use np.select to assign values to it using the lists as arguments\n",
    "        labeled_data['label'] = np.select(conditions, values)\n",
    "        \n",
    "        return labeled_data\n",
    "\n",
    "\n",
    "\n",
    "    def store_data(self) ->pd.DataFrame:\n",
    "        #self.parsed_data.to_csv(PROCESSED_DATA_PATH, index = False, header = True)\n",
    "        # csv the file so we do not need to reprocess each time\n",
    "        self.csv_processed_df_filename = 'processed_data.csv'\n",
    "        self.csv_file_loc = os.path.join(PROCESSED_DATA_PATH, self.csv_processed_df_filename)\n",
    "        data_saved = DataParser.create_label(self)\n",
    "        # df to csv\n",
    "        data_saved.to_csv(self.csv_file_loc, index = False, header = True)\n",
    "        \n",
    "        \n",
    "\n",
    "    def sub_dataframe(self) ->pd.DataFrame:\n",
    "        final_dataframe = DataParser().create_label()\n",
    "        final_dataframe = final_dataframe[['log_message', 'label']]\n",
    "        \n",
    "        return final_dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f179da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An error occurred while refreshing the network cache.: ConnectTimeout: Request to http://10.100.0.</td>\n",
       "      <td>network cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An error occurred while refreshing the network cache.: ConnectTimeout: Request to http://10.100.0.</td>\n",
       "      <td>network cache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            log_message  \\\n",
       "0    An error occurred while refreshing the network cache.: ConnectTimeout: Request to http://10.100.0.   \n",
       "1    An error occurred while refreshing the network cache.: ConnectTimeout: Request to http://10.100.0.   \n",
       "\n",
       "           label  \n",
       "0  network cache  \n",
       "1  network cache  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataParseInstance = DataParser()\n",
    "data2 = dataParseInstance.sub_dataframe()\n",
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df02c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,../scripts/preparation//py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
